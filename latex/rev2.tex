\section{Reviewer 2}\label{ref2}
\subsection{Measurement Clusterization vs Repetition}
\RC I will start by saying measurement clusterisation is not
well-defined in this paper. On page 1, it is referred to as two sets
of measurements that are almost indistinguishable from one
another. However, the setup for Corollary 11 implicitly defines
measurement clusterisation as repeated measurements. The latter
definition matches the references of \cite{fedorov1996} and
\cite{nyberg2012}. So I will assume for the rest of this review that,
measurement clusterisation refers to repeated measurements.

\AR I appreciate the comment, I fixed the relevant line in the
manuscript.


\RC Nearly all textbooks on classical design of experiments
(e.g.~\cite[Section 1.2.4]{morris2011}) will feature a section with
the three words randomisation, blocking and repetition: the important
principles of design of experiments.  In these texts, repeated
measurements are considered to be a beneficial property of a
design. Interestingly, when optimal designs are found, they are often
found to have repeated measurements. The paper does not explain why
the author thinks repeated measurements (measurement clusterisation)
is an undesirable property.

\AR I do not view clusterization as an undesired property, I only
mentioned many authors consider it to be undesirable. I have added a
paragraph contrasting repetition and replication with clusterization
and why I believe they may be different:


\begin{quote}
  Clusterization should not be confused with either repetition nor
  with replication, which are commonly viewed as beneficial and even
  necessary aspects of an optimal design \cite{fisher1949design,
    morris2011, schafer2001replication}. For example,
  \cite{fisher1949design} in his famous milk and tea experiment,
  suggested that repetition is a "way of enlarging the experiment and,
  thereby, increasing its sensitiveness". In another example,
  \cite{fay2000rainfall} measured the effect of rainfall on grass
  growth in plots of land. The experiment involved fifteen "rainfall
  manipulation shelters", where "Four rainfall manipulation treatments
  (three replicates) then were assigned to 12 of the plots". While it
  seems reasonable for the researchers to replicate the phenomenon
  they are trying to study, clusterization is different: a clustered
  design in the rainfall experiment would imply the researchers should
  take a repeated measurement \emph{on the same plot}, at the expense
  of measuring grass growth in other plots. In sharp contrast to
  repetition and replication, clusterization is highly nonintuitive
  and we will see that its origins run considerably deeper.
\end{quote}



\RC If one looks at, for example, \cite{fedorov1996} and
\cite{nyberg2012}, it is an undesirable property because they are
interested in sensor location, and two or more sensors cannot be in
the same location. However, there are many experiments where repeated
measurements are possible, and are therefore optimal

\AR I believe that even in an application where repeated experiments
are allowed they may be unintuitive. For example, in a medical imaging
application --- repeatedly measuring a "slice" in an MRI scan might
seem suboptimal to some (of course this is subjective).



\RC (if the model is correct, which it won’t be).

\AR I think this is a great point. I believe clusterization may imply
a model is somehow inadequate:

\begin{quote}
  Lastly, we believe that when clusterization arises, it should
  serve as a warning sign to practitioners. In the inverse problem of
  the 1D heat equation, clusterization occurs primarily because
  Laplacian eigenvectors \emph{do not} decay in
  $\Omega$. Consequently, measuring $u(x_1, T)$ at some point $x_1 \in
  \Omega$ provides information about $u(x_2,T)$ for distant points
  $x_2 \in \Omega$. Intuitively, this should not occur: for small $T$,
  the heat distribution at $x_1$ should give very little knowledge on
  the heat distribution at $x_2$. This behavior stems from a
  well-known property of the heat equation: it allows information to
  spread \emph{instantly} across the computational domain
  \cite{renardy2006PDE}. In reality, heat (and information) propagate
  at finite speeds. Of course, the known physical barrier for
  information spread is the speed of light, but we expect heat to
  spread considerably slower: heating an Olympic pool at one end
  should have no immediate effect on the temperature at the other end.
  
  Our choice of prior is also a potential major contributor to
  clusterization. Our choice of Gaussian prior similarly implies
  information is shared between distant locations in $\Omega$. Thus,
  we suggest refraining from choosing Gaussian priors with inverse
  Laplacian covariance operators. Rather, non-Gaussian priors could be
  employed instead \cite{hosseini2017, hosseini2019}.

  We believe that the emergence of clusterization in this context is
  thus non-physical, arising from the way the inverse problems we
  consider are phrased. Clusterization therefore indicates that the
  underlying mathematical / Bayesian model is overly permissive and
  fails to capture crucial physical constraints of the problem. We
  suggest that when clusterization occurs, practitioners should
  consider alternative models where information is localized in space
  and travels at finite speed in the medium. Such models may not only
  provide more physically accurate and meaningful results but may also
  mitigate the issue of clusterization.
\end{quote}



\RC An example, is a chemical engineering experiment where one wishes
to learn the relationship between a series of variables and yield of a
chemical reaction. The experiment will involve specifying the
variables, and measuring the yield (the observation) after a specified
period of time. This process is then duplicated with a potentially
different set of variables.  It is perfectly possible to have repeated
variables.

\AR I agree that the problem with clustered designs depends on the
application. However, in the chemical engineering experiment
mentioned, it is possible that an optimal design will require two
simultaneous measurements of the same experiment. This is an example
of a clustered design that seems unintuitive.

 
\RC The author needs to make clear that they are considering
experiments where repeated measurements are impossible. Admittedly,
this consideration is implicit in the paper, for example, the examples
given on page 1. However, it needs to be made explicit in the Abstract
and the first paragraph of the paper.

\AR I do not refrain from considering experiments where repeated
measurements are possible. I am giving insight on why such designs
arise, since many authors view repeated measurements as non-intuitive.

  
\RC The paper explains why repeated measurements can be optimal
(answer to Question 3). The author should expand on this and draw the
link with how repeated measurements are, typically, regarded as
desirable in classical design of experiments for finite
dimensions.

\AR Thank you for this suggestion. I added context, see below:

\begin{quote}
  asdfasdf
\end{quote}

\RC See for example, the discussion of the relationship between
Caratheodory’s Theorem and the number of support points in \cite[page
  139]{pronzatoPazman2013}. The support points are the unique design
points, so if this is less than $m$, then there are repeated design
points.
  
\AR I appreciate this insightful comment and reference. The arguments
presented there do not directly apply to the setup I suggest in my
paper. Thus, I have made some modifications. I was not able to find a
better way to apply these arguments in the current setup:

\begin{quote}
  \input{caratheodory}
\end{quote}
%% Firstly, the argument in \cite{pronzatoPazman2013} relies on the
%% assumption that $\theta$ --- the parameter we seek to infer --- is
%% $p$-dimensional. However, the setup I suggest is
%% infinite-dimensional. E.g.~in the generic model I propose, the
%% parameter is in $\hilo$, which is assumed an infinite-dimensional
%% Hilbert space. Similarly, the initial condition $u_0$ we try to infer
%% in the inverse problem of the heat equation is in some function space
%% over $\Omega=[0,1]$. Even if we discretize $\Omega$ and consider a
%% finite-dimensional problem, the number of discretization points would
%% be at least a hundred. So even the bound $m \leq p=100$ suggested in
%% \cite[Section 5.3.1]{pronzatoPazman2013} is not very meaningful when
%% we allow only $\approx 6$ measurements. Indeed, discretization points
%% are cheap and measurements are expensive so the number of
%% discretization points will always be considerably larger than the
%% number of allowed measurements. Thus, I do not see how the bound
%% suggested will be informative. Respectfully I choose not to explore
%% your suggestion in the manuscript.

%% We can bypass the fact that $p$ tends to be large by recalling that
%% Theorem \ref{thm:char} implies

\subsection{Context}
\RC The paper lacks discussion on context. I read the answers to the
three questions and thought “So what?”  What are the implications to
statistical practice, or experimental science, of these findings?

\AR I really appreciate this comment. I added an Implications
  section; its text is copied below:

  
  
  \begin{quote}
    % \input{implications}
  \end{quote}
  



\RC The presentation of the paper does not help. The results are
presented with no explanation or intuition. It might be better to
relegate much of the mathematical detail to Supplementary Material and
use the main manuscript for exposition.

\AR Thanks for this comment. I considerably expanded the
  introduction and delegated many proofs to the Supplementary.


\subsection{Avoiding measurement clusterisation}
\RC The approaches to avoid measurement clusterisation, described on page
3, are described as pragmatic and "fundamentally altering the optimal
design problem".

\RC Firstly, this is not strictly true. Suppose measurements correspond to
time, it is not possible to take two of more observations at the same
time, and there should be a minimum time period between measurements.
Implementing this minimum time period is not pragmatic, rather it is
characterising the application correctly. One could imagine a similar
thing occurs with the electrode locations on the skin in impedance
tomography: the physical size of the sensor imposes a minimum
distance between sensors.

\AR To a certain extent I agree: the impossibility of taking identical
measurements is indeed natural. However, this is not encoded in the
mathematical formulation of the problem. One can then take one of two
approaches: either accept what the mathematics suggest, even if it
counterintuitive, or find ways to circumvent the mathematics because
the result seems non-intuitive.


\RC Secondly, the paper seems to suggest “imposing correlations
between observations” as a solution. However, isn’t this imposition
pragmatic as well? I suppose it is argued that the $\obs \eps'$ term
is accounting for model error: but it is still pragmatic: the data
acquisition given by equation (1) is not the true data-generating
process.

\AR I do not support imposing correlations in the paper, I just
used correlations to show how my framework can be used to rigorously
prove what is widely accepted. Other referees also understood that the
paper endorses imposing correlations and I accept that this is my
error in writing. I added a clause clearing the issue.


\begin{quote}
  It is important to note that we do not view clustered designs as
  undesirable, nor do we believe it should be avoided at
  all. Clusterization is a peculiar phenomenon and it is perfectly
  reasonable for someone to argue against the D-optimality criterion
  based on the fact that it results in clustered designs. We have
  seen, however that there is a perfectly reasonable explanation for
  clusterization. We have shown that clusterization is an inevitable
  consequence of having a problem with some modes where uncertainty
  decays faster than others.
\end{quote}


\subsection{Minor comments}
\RC The author uses two different forms of asterisk: one for
optimality of the design (e.g. Definition 3) and one for the
adjoint. Suggest changing the one for optimality.

\AR I changed $\obs^\star$ to $\opt$.

%% \begin{quote}
%%   \begin{definition}\label{def:d_optimality}
%%     We say \DIFdelbegin \DIFdel{\( \obs^{\star} \)}\DIFdelend
%%     \DIFaddbegin \DIFadd{alive}\DIFaddend

%%     \(\opt\) is \emph{D-optimal} if \(\opt =
%%     \argmax_{\obs} \tar(\obs)\), where entries of \(\obs \in (\hilo^*)^m\)
%%     are constrained to some allowed set of measurements in \(\hilo^*\).
%%   \end{definition}
%% \end{quote}
  
\RC I do not like the use of the term measurements as used in the
paper. The measurements are the $\data$’s since these are a result of
measuring a physical quantity. However, the paper refers to the
quantities that are controlled as the measurements.

\AR I was not able to find a better term to replace "measurements", so
I stuck to it.

  
\RC Proof of Proposition 12 uses $\eps$ as part of the regularisation
trick but this has been used previously for error (e.g. equation (1)).
  
\AR I changed it to $\nu$. You will not find the revised proof in the
manuscript since I moved it to the Supplementary.

