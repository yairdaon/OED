\documentclass{amsart}
\input{definitions}


\begin{document}

\section{Editor in Chief}
Personally I like the paper, but it represents a somehow unusual
submission for Bayesian Analysis, and I am worried about it being of
sufficient general interest for the broad readership of the
journal. Still, in agreement with the AE, we decided to give the
author the possibility to revise the paper. However, I must stress
that there is no guarantee of a successful outcome, which will solely
depend on the quality of the revision. In particular:

\begin{description}
  \item[a] the Introduction is to be made accessible to the whole BA
    readership;
  \item[b] the motivation and the practical statistical implications are to be
    developed and discussed;
  \item[c] the contribution has to be better contextualized with
    respect to the literature in both inverse problems and D-optimal
    designs;
  \item[d] numerical evidence and code, mentioned in the paper
    but actually not provided, need to be made available;
  \item[e] the mathematical derivations have to be watertight and some
    clarifications are needed in this respect (see Report of Referee
    3).

\end{description}


\section{Associate Editor}
The three referees found merits and interest in your work, but also
pointed out several major issues to be addressed. Of particular
concern to me, the paper's exposition jumps too quickly into the
formulation / maths without giving a proper intuition and
context. This makes the paper less accessible to readers who aren't
already quite familiar with inverse problems (which are introduced
with very little preamble, and it's not even immediately explicit what
are the parameters being learned) and optimal experimental design.

A referee makes valid points as to whether clusterization of
measurements is a problem in general, when in fact in can be an
appealing feature in some settings, and another referee asks whether
D-optimal designs should be abandoned altogether. The exposition needs
to discuss these high-level issues, and introduce the related
literature and results appropriately, to give the work proper
context. Altogether, I think that your work has the potential to make
a good contribution to Bayesian analysis, but as it currently stands
significant work is needed.



\section{Reviewer 1}
This paper explains a common practical issue: the cause of
clusterization in Bayesian D-optimal designs in infinite dimensions
and why adding a correlated measurement process decluster the design
points. Its theoretical results are valuable to the field of inverse
problems/uncertainty quantification and the conclusions should be
useful to practitioners in this field.

\answer: I appreciate the kind words.

However, I feel changing the assumption from independent to correlated
measurements is quite artificial: people tweak a data generation
process assumption to solve an optimal design problem, and the author
just takes the assumption as it is. Since the author proves the
clusterization issue under the independent measurement assumption, I
expect the author to go deeper and explain why an ordinary data
generation assumption + a common optimal design leads to a
“suboptimal” design? Not just by the mathematical proof, but from an
information theory point of view. For example, does the redundancy
points mean additional points does not reduce the variance of the
estimation at all? If that’s the case, how does correlated measurement
assumption “help” with it?

\answer: Thanks for your questions. I am not a proponent of using
correlated noise, I just wanted to show the usefullness of my model by
rigorously proving how correlated noise mitigates clusterization. I
have added several lines clearing this issue.


\section{Reviewer 2}
\subsection{Measurement Clusterization vs Repetition}
I will start by saying measurement clusterisation is not well-defined
in this paper. On page 1, it is referred to as two sets of
measurements that are almost indistinguishable from one
another. However, the setup for Corollary 11 implicitly defines
measurement clusterisation as repeated measurements. The latter
definition matches the references of Fedorov (1996) and Nyberg et al
(2012). So I will assume for the rest of this review that, measurement
clusterisation refers to repeated measurements.

\answer: 

Nearly all textbooks on classical design of experiments (e.g. Morris,
2011, Section 1.2.4) will feature a section with the three words
randomisation, blocking and repetition: the important principles of
design of experiments.  In these texts, repeated measurements are
considered to be a beneficial property of a design. Interestingly,
when optimal designs are found, they are often found to have repeated
measurements. The paper does not explain why the author thinks
repeated measurements (measurement clusterisation) is an undesirable
property.

\answer: I do not view clusterization as an undesired property, I only
mentioned many authors consider it to be undesirable. I have added a
section contrasting repetition and replication with clusterization and
why I believe they may be different.

If one looks at, for example, Fedorov (1996) and Nyberg et
al (2012), it is an undesirable property because they are interested
in sensor location, and two or more sensors cannot be in the same
location. However, there are many experiments where repeated
measurements are possible, and are therefore optimal (if the model is
correct, which it won’t be). An example, is a chemical engineering
experiment where one wishes to learn the relationship between a series
of variables and yield of a chemical reaction. The experiment will
involve specifying the variables, and measuring the yield (the
observation) after a specified period of time. This process is then
duplicated with a potentially different set of variables.  It is
perfectly possible to have repeated variables.

\answer: again 

\begin{enumerate}
 
\item The author needs to make clear that they are considering
  experiments where repeated measurements are impossible. Admitedly,
  this consideration is implicit in the paper, for example, the
  examples given on page 1. However, it needs to be made explicit in
  the Abstract and the first paragraph of the paper.

  \answer: I do consider experiments where repeated measurements are
  possible. I am giving insight on why such designs are useful, even
  though repeated measurements may be non-intuitive in certain
  settings.
  
\item The paper explains why repeated measurements can be optimal
  (answer to Question 3). The author should expand on this and draw
  the link with how repeated measurements are, typically, regarded as
  desirable in classical design of experiments for finite
  dimensions. See for example, the discussion of the relationship
  between Caratheodory’s Theorem and the number of support points in
  Pronzato \& Pazman (2013, page 139). The support points are the
  unique design points, so if this is less than m, then there are
  repeated design points.

  \answer: great comment
\end{enumerate}

\subsection{Context}
The paper lacks discussion on context. I read the answers to the three
questions and thought “So what?”  What are the implications to
statistical practice, or experimental science, of these findings?  The
presentation of the paper does not help. The results are presented
with no explanation or intuition. It might be better to relegate much
of the mathematical detail to Supplementary Material and use the main
manuscript for exposition.

\subsection{Avoiding measurement clusterisation}
The approaches to avoid measurement clusterisation, described on page
3, are described as pragmatic and "fundamentally altering the optimal
design problem".

Firstly, this is not strictly true. Suppose measurements correspond to
time, it is not possible to take two of more observations at the same
time, and there should be a minimum time period between measurements.
Implementing this minimum time period is not pragmatic, rather it is
characterising the application correctly.  One could imagine a similar
thing occurs with the eletrode locations on the skin in impedence
tomography: the physical size of the sensor imposes a miniumum
distance between sensors.

Secondly, the paper seems to suggest “imposing correlations between
observations” as a solution. However, isn’t this imposition pragmatic
as well? I suppose it is argued that the $\obs \eps′$ term is
accounting for model error: but it is still pragmatic: the data
acquisition given by equation (1) is not the true data-generating
process.


\subsection{Minor comments}
\begin{itemize}
\item The author uses two different forms of asterisk: one for
  optimality of the design (e.g. Definition 3) and one for the
  adjoint. Suggest changing the one for optimality.
\item I do not like the use of the term measurements as used in the
  paper. The measurements are the $\data$’s since these are a result of
  measuring a physical quantity. However, the paper refers to the
  quantities that are controlled as the measurements.
\item Proof of Proposition 12 uses $\eps$ as part of the
  regularisation trick but this has been used previously for error
  (e.g. equation (1)).
\end{itemize}




\section{Reviewer 3}
The paper studies Bayesian D-optimal design (that is, the task of
allocating measurements in order to maximise the Kullback-Leibler
divergence between the prior and posterior disribution) in an inverse
regression type model in Hilbert spaces with Gaussian measurements
errors. For Gaussian priors, the paper provides a characterisation of
the optimality criterion and the optimal design. Some conclusions
about the phenomenon of clusterisation of measurements known in
literature are then drawn.

While the results in the paper provide some novel insights on the
topic, I believe the current version of the manuscript is far from the
standard required by Bayesian Analysis. Let me raise immediately my
main concern: on p.4 the author describes the generality of
measurements clusterisation as the first main question being explored,
which is answered via, quoting, "randomized numerical simulations that
exhibit clusterization more than 95\% of the time (see the code in
supplementary material)". However, in the version of the supplementary
materials I had access to there is no further mention of these
numerical simulations and results; only a link to a Github repository
is provided, which is however not functioning. Evidently, this issue
needs to be fixed before any future consideration can be given to the
manuscript. For example, a detailed description of the repeated
experiments could be provided either in the main article or in the
supplement, with tables indicating the various values of the
parameters for the simulations and the precise percentages
obtained. Also, the code needs to be publicly available for
reproducibility.

\subsection{Further comments}
I have a number of further comments in regards to the results and the overall presentation of
the manuscript.
\begin{itemize}
\item D-optimal design vs. statistical recovery rates: being more
  familiar with the statistical inverse problem literature than with
  D-optimal design, the clusterisation phenomenon demonstrated in this
  paper raises the question as to wether consistent recovery of the
  unknown (m in the notation of this paper) is possible under this
  choice. All the results I am aware of either assume white
  noise/equally spaced design (e.g. [1]) or measurement loctions
  sampled uni- formly at random (e.g. [2]). There are also some
  results with more general design under conditions on the
  fill-distance of the grid (e.g. [3]). All of these specifically
  prevent clusteri- sation, which is key to the statistical
  analysis. Hence, it is not clear to me even if D-optimal design
  should be pursued at all, if it indeed it leads to clusterisation as
  implied by the present 1paper. I think a discussion on this would be
  illuminating for the reader and help draw a connection to the
  broader statistical inverse problems literature.

\item Figure 1: It is hard to descern whether the measurements
  locations are perfectly overlapping or just very closely
  placed. Perhaps using dots with numbers here would help the
  readability.

  Answer: It is impossible to visually discern the measurements, even
  when resolution is increased.

\item Experiment with the 1D heat equation: the experiment showcases
  some interesting phenomena, but also raises many questions. For
  instance: I would expect the dimensionality of the working domain
  (here the unit interval [0, 1]) to play a role, since larger
  dimension allow for higher freedom in placing the design points.

  Answer: That is a great point! I added the followng discussion: 

\item Further, a dimensionality effect should also arise directly from
  Theorem 1 via the prior covariance eigenvalues: in the experiment
  the prior covariance operator is set to be equal to the inverse
  Laplace operator $(−\Delta)^{−1}$ . In d-dimensional domains, its
  eigenvalues $\lambda_j$ are known to follow Weyl’s asymptotics,
  growing as $j^{2/d}$, which should then impact the index after
  which the eigenvalues are ‘thresholded’ by the procedure.

\item Also, it should be relatively easy here to also study empirically the effect of the correlated
error model in preventing clusterisation. Investigating all these issues in the context of the
presented numerical set up would considerably enlarge the breath of the present work.

\item I found very hard to understand Theorem 1 immediately at the end
  of Section 1, as all the necessary background is introduced only
  later. Since the same result is also stated and proved in Section 5,
  I would consider cutting it from Section 1. The paragraphs in p.4
  and 5 already do a good job presenting the results, and the
  repetition of the formal statement does not seem necessary here.

\item Denoting the optimal design in Theorem 1 by simply O is somewhat confusing, cf. the
equation in the second item. Perhaps a separate notation such as Ō would help readability.

\item Section 1.2 seems altogether unnecessary; the inverse regression model considered in the
paper are a modelisation of many real-world phenomena, and they are routinely studied in
statistical papers.

Answer: Thanks for this comment but I would rather keep this section
here since...


\item What does ‘strongly smoothning’ operator means in the thid line of Section 2.1?

\item Section 4: the conclusion reached at the end of the section on
  p.15 seem to imply that in the noiseless limit, repeating any
  measurement does not improve the objective criterion, if corre-
  lated error model are present. Is it clear however that adding any
  (non-reapted) measurement always strictly increases it? I.e., there
  could be situations where adding one measurement does not change the
  value of the optimised criterion? Also, can the conclusion drawn
  here be extended to the case of noisy observations σ > 0?

\item At the end of Section 4 on p.15 it is mentioned that $\tar$ is not
  defined for $\sigma^2= 0$, but in the latter case, could not a Gaussian
  posterior measure be still defined as in Gaussian process
  regression, e.g.[4]

\item Theorem 1 is expressed in terms of the prior covariance matrix,
  which is a user specified quantity. Hence, it seems to me that all
  sort of design behaviour under the D-optimal crite- rior can occur
  by engineering the prior. It would perhaps be informative to study
  in more details some representative example of inverse problem and
  Gaussian prior. For example, the recovery of the initial condition
  with the ‘Matérn-like’ Gaussian prior laid out in the sup- plement
  are good candidates. For these it is still not clear how the
  conclusion from Theorem 1 translates into the Figure 1, also because
  I am unsure about the applicability of the result to point
  evaluations. In particular, how the conclusion that with m = 4
  measurements the D-optimal procedure will aim to ignore the third
  and fourth eigenvalue/function was drawn?
\end{itemize}

\end{document}
