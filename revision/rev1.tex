\section{Reviewer 1}\label{ref1}
\RC This paper explains a common practical issue: the cause of
clusterization in Bayesian D-optimal designs in infinite dimensions
and why adding a correlated measurement process decluster the design
points. Its theoretical results are valuable to the field of inverse
problems/uncertainty quantification and the conclusions should be
useful to practitioners in this field.

\AR I appreciate the kind words.


\RC However, I feel changing the assumption from independent to correlated
measurements is quite artificial: people tweak a data generation
process assumption to solve an optimal design problem, and the author
just takes the assumption as it is.

\AR If I understand correctly --- I completely agree. I added text
emphasizing that I do not endorse using correlated errors:

\begin{quote} % Avoid
Given the above discussion, it is our belief that the methods
suggested by other authors to avoid clusterization are merely
overlooking the problem. We do not view clustered designs as
inherently bad on their own. Rather, we suggest that if a clustered
design arises, a practitioner should revisit their modeling
assumptions --- specifically, their choice of prior and model
linearization. If the practitioner is confident in their assumptions,
then clustered designs should be avoided only to the extent
necessitated by the physical measuring apparatus.
\end{quote}

\RC Since the author proves the clusterization issue under the independent
measurement assumption, I expect the author to go deeper and explain
why an ordinary data generation assumption + a common optimal design
leads to a “suboptimal” design?

\AR In my view this is a generic phenomenon that arises from a choice
of a linear(ized) model and a Gaussian prior:
\begin{quote}% Gaussian
  One potential cause of clusterization is our choice of prior. Gaussian
priors, coupled with a Gaussian likelihood and a linear forward
problem give rise to a closed form solution for the posterior via
conjugacy. As we show in Section \ref{subsec:lemma_sims}, such
assumptions generically give rise to clusterization. While an
assumption of a Gaussian likelihood is standard, and rooted in the
central limit theorem, an assumption of Gaussian prior is merely a
matter of convenience. Therefore, we advise any practitioner who
encounters clusterization to replace their Gaussian priors with
non-Gaussian priors instead \cite{hosseini2017, hosseini2019}.
\newline %% Linearization
Another potential cause of clusterization is linearization. While in a
real applications the model is not necessarily linear, some authors
consider a linearized version of their model when seeking optimal
designs \cite{fedorov1996, neitzel2019sparse}. Our analysis then shows
that the linearity of the forward problem is also an important
ingredient in giving rise to clustered desgins. Therefore, our advice
to practitioners is to avoid linearization, and find D-optimal designs
via other methods, e.g.~the sampling method of \cite{ryan2003}.
\end{quote}


\RC Not just by the mathematical proof, but from an information theory
point of view. For example, does the redundancy points mean additional
points does not reduce the variance of the estimation at all? If
that’s the case, how does correlated measurement assumption “help”
with it?

\AR For any nonzero observation error $\sigma^2 > 0$, repeated
measurements will indeed reduce the signal-to-noise ratio of the
measurement and result in an increase of the design criterion. I
discuss this issue below:

\begin{quote} %% Replication 1
  Clusterization should not be confused with replication. Replication
requires that the experimentalist executes multiple trials under
circumstances that are \emph{nominally identical} \cite[Section
  1.2.4]{morris2011}. Replication is commonly viewed as a beneficial
and even necessary aspect of optimal experimental design
\cite{fisher1949design, morris2011, schafer2001replication}. Similarly
to a design implementing replication, a clustered design reduces the
signal-to-noise ratio of the repeated measurements
\cite{telford2007brief}. The difference is that a clustered design
takes repeated measurements at the expense of other quantities not
measured at all.
\newline %% Replication 2
For example, \cite{fisher1949design}, suggested repeating his famous
milk and tea experiment in order "to be able to demonstrate the
predominance of correct classifications in spite of occasional
errors". Unfortunately, in the experiments we consider, replication is
impossible. For example, in the MRI problem, we cannot generate an
individual nominally identical to the one we wish to scan.
\newline %% Replication 3
To further illustrate the difference between replication and
clusterization, consider an experiment measuring the effect of
rainfall on grass growth \cite{fay2000rainfall}. The experiment
involved four rainfall manipulation "treatments" (i.e.~simulating
different timing and quantity of rainfall), each replicated three
times over a different plot of land. Indeed, it seems reasonable for
researchers to replicate the phenomenon they are trying to study. A
clustered design in such an experiment would imply the researchers
should take a repeated measurement \emph{on the same plot}, at the
expense of measuring grass growth in other plots. To conclude our
short discussion on replication vs.~clusterization: these are
fundamentally different concepts and even though replication is quite
intuitive, it is inapplicable to the inverse problems we consider in
this manuscript.
\end{quote}


